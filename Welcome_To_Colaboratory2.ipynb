{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRAHIMLOUARDI/movie-web-app/blob/main/Welcome_To_Colaboratory2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "metadata": {
        "id": "2RcucfGkil5R"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Input, TimeDistributed, Dense, Activation, RepeatVector, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "\n",
        "# Path to translation file\n",
        "path_to_data = '/content/fra.txt'\n",
        "\n",
        "# Read file\n",
        "translation_file = open(path_to_data,\"r\", encoding='utf-8') \n",
        "raw_data = translation_file.read()\n",
        "translation_file.close()\n",
        "\n",
        "# Parse data\n",
        "raw_data = raw_data.split('\\n')\n",
        "pairs = [sentence.split('\\t') for sentence in  raw_data]\n",
        "pairs=pairs[0:60000]\n",
        "\n"
      ],
      "metadata": {
        "id": "dl2gDN6AeCsh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pairs[11117]) jkcashiefhiwei"
      ],
      "metadata": {
        "id": "oPXP-IDWQlTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49350fdc-69f1-4939-ecce-524e86b72e8d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A recurrent neural network is a class of artificial neural networks ', 'Un réseau de neurones récurrent est une classe de réseaux de neurones artificiels']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sentence(sentence):\n",
        "    # Lower case the sentence\n",
        "    lower_case_sent = sentence.lower()\n",
        "    # Strip punctuation\n",
        "    string_punctuation = \"?\" + \"¡\" + '¿'+\".\"+\"!\"+\".\" ;\n",
        "    clean_sentence = lower_case_sent.translate(str.maketrans('', '', string_punctuation))\n",
        "   \n",
        "    return clean_sentence"
      ],
      "metadata": {
        "id": "kppzLb79oYWj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentences):\n",
        "    # Create tokenizer\n",
        "    text_tokenizer = Tokenizer()\n",
        "    # Fit texts\n",
        "    text_tokenizer.fit_on_texts(sentences)\n",
        "    return text_tokenizer.texts_to_sequences(sentences), text_tokenizer"
      ],
      "metadata": {
        "id": "FlMW2oEBpK1-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# english_sentences = [clean_sentence(pair[0]).replace(\"\\u202f\",\" \").replace(\"\\xa0\",\" \").replace(\"\\u200b\",\" \").replace(\"«\\u2009\",\" \").replace(\"\\u2009\",\" \").replace(\"\\xad\",\"\").rstrip().lstrip() for pair in pairs]\n",
        "# french_sentences = [clean_sentence(pair[1]).replace(\"\\u202f\",\" \").replace(\"\\xa0\",\" \").replace(\"\\u200b\",\" \").replace(\"«\\u2009\",\" \").replace(\"\\u2009\",\" \").replace(\"\\xad\",\"\").rstrip().lstrip() for pair in pairs]\n",
        "\n",
        "# # Tokenize words\n",
        "# fra_text_tokenized, fra_text_tokenizer = tokenize(french_sentences)\n",
        "# eng_text_tokenized, eng_text_tokenizer = tokenize(english_sentences)\n",
        "\n",
        "# print('Maximum length french sentence: {}'.format(len(max(fra_text_tokenized,key=len))))\n",
        "# print('Maximum length english sentence: {}'.format(len(max(eng_text_tokenized,key=len))))\n",
        "\n",
        "\n",
        "# # Check language length\n",
        "# french_vocab = len(fra_text_tokenizer.word_index) + 1\n",
        "# english_vocab = len(eng_text_tokenizer.word_index) + 1\n",
        "# print(\"french vocabulary is of {} unique words\".format(french_vocab))\n",
        "# print(\"English vocabulary is of {} unique words\".format(english_vocab))\n",
        "\n",
        "\n",
        "# Clean sentences\n",
        "# english_sentences = [clean_sentence(pair[0]) for pair in pairs]\n",
        "# french_sentences = [clean_sentence(pair[1]) for pair in pairs]\n",
        "english_sentences = [clean_sentence(pair[0]).replace(\"\\u202f\",\" \").replace(\"\\xa0\",\" \").replace(\"\\u200b\",\" \").replace(\"«\\u2009\",\" \").replace(\"\\u2009\",\" \").replace(\"\\xad\",\"\").rstrip().lstrip() for pair in pairs]\n",
        "french_sentences = [clean_sentence(pair[1]).replace(\"\\u202f\",\" \").replace(\"\\xa0\",\" \").replace(\"\\u200b\",\" \").replace(\"«\\u2009\",\" \").replace(\"\\u2009\",\" \").replace(\"\\xad\",\"\").rstrip().lstrip() for pair in pairs]\n",
        "\n",
        "\n",
        "# Tokenize words\n",
        "fra_text_tokenized, fra_text_tokenizer = tokenize(french_sentences)\n",
        "eng_text_tokenized, eng_text_tokenizer = tokenize(english_sentences)\n",
        "\n",
        "print('Maximum length spanish sentence: {}'.format(len(max(fra_text_tokenized,key=len))))\n",
        "print('Maximum length english sentence: {}'.format(len(max(eng_text_tokenized,key=len))))\n",
        "\n",
        "\n",
        "# Check language length\n",
        "french_vocab = len(fra_text_tokenizer.word_index) + 1\n",
        "english_vocab = len(eng_text_tokenizer.word_index) + 1\n",
        "print(\"Spanish vocabulary is of {} unique words\".format(french_vocab))\n",
        "print(\"English vocabulary is of {} unique words\".format(english_vocab))"
      ],
      "metadata": {
        "id": "FJd49T6VpQtn",
        "outputId": "06dc3fd7-607d-49a2-d7a0-84fd9696370b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum length spanish sentence: 14\n",
            "Maximum length english sentence: 12\n",
            "Spanish vocabulary is of 13638 unique words\n",
            "English vocabulary is of 7480 unique words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max_french_len = int(len(max(fra_text_tokenized,key=len)))\n",
        "# max_english_len = int(len(max(eng_text_tokenized,key=len)))\n",
        "\n",
        "# fra_pad_sentence = pad_sequences(fra_text_tokenized,max_french_len, padding = \"post\")\n",
        "# eng_pad_sentence = pad_sequences(eng_text_tokenized,max_english_len, padding = \"post\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# fra_pad_sentence = fra_pad_sentence.reshape(*fra_pad_sentence.shape, 1)\n",
        "# eng_pad_sentence = eng_pad_sentence.reshape(*eng_pad_sentence.shape, 1)"
      ],
      "metadata": {
        "id": "g6LIc2DpqRUl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_french_len = int(len(max(fra_text_tokenized,key=len)))\n",
        "max_english_len = int(len(max(eng_text_tokenized,key=len)))\n",
        "\n",
        "fra_pad_sentence = pad_sequences(fra_text_tokenized, max_french_len, padding = \"post\")\n",
        "eng_pad_sentence = pad_sequences(eng_text_tokenized, max_english_len, padding = \"post\")\n",
        "\n",
        "# Reshape data\n",
        "fra_pad_sentence = fra_pad_sentence.reshape(*fra_pad_sentence.shape, 1)\n",
        "eng_pad_sentence = eng_pad_sentence.reshape(*eng_pad_sentence.shape, 1)"
      ],
      "metadata": {
        "id": "hZuF8f2Dkbel"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lc1Ov8hhk5oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_sequence = Input(shape=(max_french_len,))\n",
        "# embedding=Embedding(input_dim=french_vocab, output_dim=256,)(input_sequence)\n",
        "\n",
        "input_sequence = Input(shape=(max_french_len,))\n",
        "embedding = Embedding(input_dim=french_vocab, output_dim=256,)(input_sequence)"
      ],
      "metadata": {
        "id": "mWBT4WhOutoR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder = LSTM(64, return_sequences=False)(embedding)\n",
        "# r_vec = RepeatVector(15)(encoder)\n",
        "# decoder = LSTM(64, return_sequences=True, dropout=0.2)(r_vec)\n",
        "# logits = TimeDistributed(Dense(english_vocab))(decoder)\n",
        "\n",
        "input_sequence = Input(shape=(max_french_len,))\n",
        "embedding = Embedding(input_dim=french_vocab, output_dim=256,)(input_sequence)\n",
        "encoder = LSTM(64, return_sequences=False)(embedding)\n",
        "r_vec = RepeatVector(max_english_len)(encoder)\n",
        "decoder = LSTM(64, return_sequences=True, dropout=0.2)(r_vec)\n",
        "logits = TimeDistributed(Dense(english_vocab))(decoder)"
      ],
      "metadata": {
        "id": "YFefu6Nf4hDa"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_dec_model = Model(input_sequence, Activation('softmax')(logits))\n",
        "enc_dec_model.compile(loss=sparse_categorical_crossentropy,\n",
        "              optimizer=Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "enc_dec_model.summary()"
      ],
      "metadata": {
        "id": "EdayUG1V4kUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6294429-a82a-4be6-b64a-bd008c494b0e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 14)]              0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 14, 256)           3491328   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 64)                82176     \n",
            "                                                                 \n",
            " repeat_vector_1 (RepeatVect  (None, 12, 64)           0         \n",
            " or)                                                             \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 12, 64)            33024     \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 12, 7480)         486200    \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 12, 7480)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,092,728\n",
            "Trainable params: 4,092,728\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "STEPS_PER_EPOCH = len(fra_pad_sentence) / BATCH_SIZE\n",
        "SAVE_PERIOD = 10\n",
        "\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\"model/weights1.{epoch:02d}.hdf5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto', save_freq=int(SAVE_PERIOD * STEPS_PER_EPOCH))"
      ],
      "metadata": {
        "id": "wwSe7dqOgZfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_results = enc_dec_model.fit(fra_pad_sentence, eng_pad_sentence, batch_size=32, epochs=70)\n"
      ],
      "metadata": {
        "id": "-n0L3m3h4rAn",
        "outputId": "01a77818-e5ae-47a7-9c31-cbe193f26fb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "1875/1875 [==============================] - 25s 9ms/step - loss: 2.1979 - accuracy: 0.7037\n",
            "Epoch 2/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 1.9422 - accuracy: 0.7084\n",
            "Epoch 3/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 1.9163 - accuracy: 0.7091\n",
            "Epoch 4/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 1.7336 - accuracy: 0.7299\n",
            "Epoch 5/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 1.5062 - accuracy: 0.7564\n",
            "Epoch 6/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 1.3447 - accuracy: 0.7755\n",
            "Epoch 7/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 1.2248 - accuracy: 0.7891\n",
            "Epoch 8/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 1.1312 - accuracy: 0.7992\n",
            "Epoch 9/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 1.0523 - accuracy: 0.8076\n",
            "Epoch 10/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.9830 - accuracy: 0.8150\n",
            "Epoch 11/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.9213 - accuracy: 0.8211\n",
            "Epoch 12/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.8649 - accuracy: 0.8280\n",
            "Epoch 13/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.8127 - accuracy: 0.8338\n",
            "Epoch 14/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.7646 - accuracy: 0.8404\n",
            "Epoch 15/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.7208 - accuracy: 0.8466\n",
            "Epoch 16/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6811 - accuracy: 0.8527\n",
            "Epoch 17/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6435 - accuracy: 0.8584\n",
            "Epoch 18/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6098 - accuracy: 0.8641\n",
            "Epoch 19/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5789 - accuracy: 0.8693\n",
            "Epoch 20/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5527 - accuracy: 0.8736\n",
            "Epoch 21/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5262 - accuracy: 0.8785\n",
            "Epoch 22/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5038 - accuracy: 0.8825\n",
            "Epoch 23/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4837 - accuracy: 0.8862\n",
            "Epoch 24/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4648 - accuracy: 0.8895\n",
            "Epoch 25/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4486 - accuracy: 0.8927\n",
            "Epoch 26/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4327 - accuracy: 0.8958\n",
            "Epoch 27/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4174 - accuracy: 0.8981\n",
            "Epoch 28/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4044 - accuracy: 0.9012\n",
            "Epoch 29/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3926 - accuracy: 0.9036\n",
            "Epoch 30/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3811 - accuracy: 0.9054\n",
            "Epoch 31/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3705 - accuracy: 0.9078\n",
            "Epoch 32/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3589 - accuracy: 0.9106\n",
            "Epoch 33/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3514 - accuracy: 0.9115\n",
            "Epoch 34/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3432 - accuracy: 0.9135\n",
            "Epoch 35/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3345 - accuracy: 0.9151\n",
            "Epoch 36/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3274 - accuracy: 0.9165\n",
            "Epoch 37/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3200 - accuracy: 0.9181\n",
            "Epoch 38/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3137 - accuracy: 0.9190\n",
            "Epoch 39/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3065 - accuracy: 0.9208\n",
            "Epoch 40/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3014 - accuracy: 0.9216\n",
            "Epoch 41/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2961 - accuracy: 0.9229\n",
            "Epoch 42/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2899 - accuracy: 0.9241\n",
            "Epoch 43/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2864 - accuracy: 0.9248\n",
            "Epoch 44/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2807 - accuracy: 0.9259\n",
            "Epoch 45/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2767 - accuracy: 0.9268\n",
            "Epoch 46/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2718 - accuracy: 0.9277\n",
            "Epoch 47/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2674 - accuracy: 0.9285\n",
            "Epoch 48/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2642 - accuracy: 0.9291\n",
            "Epoch 49/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2592 - accuracy: 0.9304\n",
            "Epoch 50/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2572 - accuracy: 0.9309\n",
            "Epoch 51/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2527 - accuracy: 0.9318\n",
            "Epoch 52/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2505 - accuracy: 0.9321\n",
            "Epoch 53/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2459 - accuracy: 0.9332\n",
            "Epoch 54/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2426 - accuracy: 0.9343\n",
            "Epoch 55/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2413 - accuracy: 0.9342\n",
            "Epoch 56/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2376 - accuracy: 0.9351\n",
            "Epoch 57/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2345 - accuracy: 0.9355\n",
            "Epoch 58/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2326 - accuracy: 0.9360\n",
            "Epoch 59/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2302 - accuracy: 0.9366\n",
            "Epoch 60/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2270 - accuracy: 0.9375\n",
            "Epoch 61/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2255 - accuracy: 0.9376\n",
            "Epoch 62/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2222 - accuracy: 0.9382\n",
            "Epoch 63/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2201 - accuracy: 0.9385\n",
            "Epoch 64/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2183 - accuracy: 0.9390\n",
            "Epoch 65/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2164 - accuracy: 0.9395\n",
            "Epoch 66/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2145 - accuracy: 0.9399\n",
            "Epoch 67/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2121 - accuracy: 0.9403\n",
            "Epoch 68/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2104 - accuracy: 0.9408\n",
            "Epoch 69/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2079 - accuracy: 0.9415\n",
            "Epoch 70/70\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2065 - accuracy: 0.9417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_dec_model.save('finalfinal.h5')"
      ],
      "metadata": {
        "id": "oXIV3Yne_LRk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "new_enc_dec_model = tf.keras.models.load_model('my_model_v2.h5')\n",
        "\n"
      ],
      "metadata": {
        "id": "gyK75ot6DBSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=[\"Un réseau de neurones récurrent est une classe de réseaux de neurones artificiels\"]\n",
        "y=fra_text_tokenizer.texts_to_sequences(x)\n",
        "z=pad_sequences(y, max_french_len, padding = \"post\")\n",
        "\n",
        "# print(y)\n",
        "z=np.reshape(z,(1,max_french_len,1))\n",
        "\n",
        "def logits_to_sentence(logits, tokenizer):\n",
        "\n",
        "    index_to_words = {idx: word for word, idx in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '' \n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
        "\n",
        "index = 8000\n",
        "# print(\"The english sentence is: {}\".format(english_sentences[index]))\n",
        "print(\"The french sentence is: {}\".format(x[0]))\n",
        "print('The predicted sentence is :')\n",
        "print(logits_to_sentence(enc_dec_model.predict(z)[0], eng_text_tokenizer))\n",
        "\n",
        "# print(fra_pad_sentence[50001:50002].shape)\n",
        "# print(z.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0BnIzzcgBQp9",
        "outputId": "2e8ec5f6-39cf-42d7-bf40-77ba98bd8fe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The french sentence is: Un réseau de neurones récurrent est une classe de réseaux de neurones artificiels\n",
            "The predicted sentence is :\n",
            "a recurrent neural network is a class of artificial neural networks \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs\n",
        "import tensorflowjs as tfjs"
      ],
      "metadata": {
        "id": "Ja9mqzaMVFfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfjs.converters.save_keras_model(new_enc_dec_model, 'content/model')"
      ],
      "metadata": {
        "id": "IS93bgLkVW69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model.zip content/model"
      ],
      "metadata": {
        "id": "iVSWkJLVWPAX",
        "outputId": "9cfe5412-030a-4ae1-d856-3299bfd813fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/model/ (stored 0%)\n",
            "  adding: content/model/model.json (deflated 77%)\n",
            "  adding: content/model/group1-shard2of3.bin (deflated 7%)\n",
            "  adding: content/model/group1-shard1of3.bin (deflated 7%)\n",
            "  adding: content/model/group1-shard3of3.bin (deflated 7%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}